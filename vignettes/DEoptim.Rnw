\documentclass[nojss,shortnames]{jss}
\usepackage{amsmath,amssymb} 
\usepackage{xspace}
%% need no \usepackage{Sweave}

\author{David Ardia \\ aeris CAPITAL AG \And Katharine M. Mullen \\ NIST 
  \And Joshua Ulrich \\ FOSS Trading \And Brian G. Peterson \\ DV Trading}

\title{\pkg{DEoptim}: An \proglang{R} Package for Global 
  Optimization by Differential Evolution}

\Plainauthor{David Ardia, Katharine M. Mullen, Joshua Ulrich, Brian Peterson} 
\Plaintitle{DEoptim: An R Package for Global Optimization by Differential Evolution} 
\Shorttitle{DEoptim: An R Package for Differential Evolution} 

\Abstract{This introduction to the \proglang{R} package \pkg{DEoptim} is 
  an abreviated version of the manuscript 
  \citet{DEoptimJSS2011}, 
  published in the \emph{Journal of Statistical Software}. 
  \pkg{DEoptim} implements the Differential Evolution algorithm
  for global optimization of a real-valued function of a 
  real-valued parameter vector. The implementation of Differential 
  Evolution in \pkg{DEoptim} interfaces with \proglang{C} code for efficiency. Moreover, the package
  is self-contained and does not depend on any other packages. 
}
\Keywords{global optimization, evolutionary algorithm, Differential Evolution, \proglang{R} software}
\Plainkeywords{global optimization, evolutionary algorithm, Differential Evolution, R software} 

\Address{
David Ardia\\
aeris CAPITAL AG, Switzerland\\
URL:~\url{http://perso.unifr.ch/david.ardia/}  \\
  
Katharine Mullen \\ 
Ceramics Division, National Institute of Standards and Technology (NIST)\\ 
100 Bureau Drive, MS 8520, Gaithersburg, MD, 20899, USA\\ 
E-mail: \email{Katharine.Mullen@nist.gov}\\

Joshua Ulrich \\ 
FOSS Trading \\ 
URL:~\url{http://fosstrading.com}  \\

Brian G. Peterson\\
DV Trading\\
E-mail: \email{brian@braverock.com}  \\ 

}

\begin{document}

\SweaveOpts{engine=R,eps=FALSE}
%\VignetteIndexEntry{DEoptim: An R Package for Differential Evolution}
%\VignetteKeywords{global optimization, evolutionary algorithm, Differential Evolution, R}
%\VignettePackage{DEoptim}

\section{Introduction}\label{intro}

Optimization algorithms inspired by the process of natural selection
have been in use since the 1950s \citep{mitchell}, and are often
referred to as {\sl evolutionary algorithms}.  The genetic algorithm
is one such method, and was invented by John Holland in the 1960s 
\citep{holland}. Genetic algorithms apply logical operations, usually on bit strings of 
fixed or variable length,
in order to perform crossover, mutation, and selection on a
population.  Over the course of successive generations, the members of
the population are more likely to represent a minimum of an objective
function.  Genetic algorithms have proven themselves
to be useful heuristic methods for global optimization, in particular
for combinatorial optimization problems.  Evolution strategies are
another variety of evolutionary algorithm, in which members of the
population are represented with floating point numbers, and the
population is transformed over successive generations using arithmetic
operations. See \citet[Section~1.2.3]{Price:Storn:Lampinen:06} for a detailed overview 
of evolutionary algorithms.

In the 1990s Rainer Storn and Kenneth Price developed an evolution strategy they termed
{\sl Differential Evolution} (DE) \citep{price}. DE is particularly
well-suited to find the global optimum of a real-valued 
function of real-valued parameters, and does not require that the function be
either continuous or differentiable.  In the roughly fifteen years
since its invention, DE has been successfully applied in a wide
variety of fields, from computational physics to operations research,
as \citet{Price:Storn:Lampinen:06} catalogue.

The \pkg{DEoptim} \citep{DEoptim} implementation of DE was motivated by 
our desire to extend the set of algorithms
available for global optimization  in the 
\proglang{R} language and environment for statistical computing 
\citep{r_env}. \pkg{DEoptim} has been published on the Comprehensive
\proglang{R} Archive Network and is available at
\url{http://cran.r-project.org/web/packages/DEoptim/}. The \pkg{DEoptim} project 
is hosted on \proglang{R}-forge at \url{https://r-forge.r-project.org/projects/deoptim/}.
Since becoming publicly available it has 
been used by a variety of authors, e.g., 
\citet{Borner:Higgins:Kantelhardt:Scheiter:07},
\citet{Higgins:Kantelhardt:Scheiter:Boerner:07},
\citet{OpsinaArango:09}, 
\citet{ArdiaBoudtCarlMullenPeterson2011} and \citet{Ardia:Ospina:Giraldo:2011} to 
solve optimization problems arising in diverse domains. Interested readers
are referred to \citet{DEoptimJSS2011} for a 
longer version of the present vignette. 
  
The recently released \pkg{RcppDE} \citep{RcppDE} package ports the \proglang{C}
code in \pkg{DEoptim} to \proglang{C++}. The documentation claims \pkg{RcppDE} is more
efficient than the \proglang{C}-based implementation in \pkg{DEoptim} version 2.0-7, but most
of the increased efficiency is attributable to a non-trivial
difference in the functionality: \pkg{RcppDE} does not pass \code{"..."} to the
objective function.  \pkg{DEoptim} version 2.0-8 incorporates several
language-independent improvements made in \pkg{RcppDE} and compares
favorably to a patched version of \pkg{RcppDE} that passes \code{"..."}.


We hope that the \proglang{R} package \pkg{DEoptim} will be fruitful 
for many users. If you use \proglang{R} or \pkg{DEoptim}, please cite the software in publications.

In the remainder of this vignette we elaborate on \pkg{DEoptim}'s
implementation and use. In Section~\ref{inex}, the package 
is introduced via a simple example.  Section~\ref{alg}
describes the underlying algorithm.  Section~\ref{imp} describes the 
\proglang{R} implementation and serves as a
user manual.

\subsection{An introductory example}\label{inex} 

Minimization of the Rastrigin function in $x \in \Re^D$
\begin{align*} 
  f(x) = \sum_{j=1}^{D} \left( x_j^2 - 10 \cos \left( 2 \pi x_j \right) 
  + 10 \right) 
\end{align*}
for $D=2$ is a common test for global optimization algorithms.  

This function is possible to represent in \proglang{R} as 

<<opt,echo=FALSE,results=hide>>=
options(prompt = "R> ")
@ 
<<rast>>=
rastrigin <- function(x) 
  10*length(x)+sum(x^2-10*cos(2*pi*x))
@ 
As shown in Figure~\ref{rast}, for $D=2$
the function has a global minimum $f(x)=0$ at the point $(0,0)$.  

<<figure1-code,echo=FALSE,results=hide>>=
library("colorspace")
library("grid")
library("lattice")
jpeg("Rastrigin1.jpg")
x <- y <- seq(-5,5,by=.1)
z <- matrix(nrow=length(x), ncol=length(y))
for(i in 1:length(x)) {
  for(j in 1:length(y)) 
    z[i,j] <- rastrigin(c(x[i],y[j]))
}
xx <- list(fontsize=list(text=15,points=10),
           par.xlab.text=list(cex=2),
           par.ylab.text=list(cex=2),
           axis.text=list(cex=2),
           par.main.text=list(cex=2),
           layout.widths=list(left.padding=.1, right.padding=.1,
             between=0),
           layout.heights=list(top.padding=.1, bottom.padding=.1,
             between=0)
           )
levelplot(z, row.values=x,column.values=y,
          col.regions=sequential_hcl(300), xlab=expression(x[1]), 
          ylab=expression(x[2]),
          par.settings=xx,
          panel=function(z,row.values,column.values,...){
            panel.levelplot(z,row.values,column.values,...);
            panel.points(0,0,pch=21,col="white",cex=2)})

dev.off()
set.seed(123) 
@


\begin{figure}[t!]
\centering
\includegraphics[width=.5\textwidth]{Rastrigin1.jpg}
\caption{A contour plot of the two-dimensional Rastrigin function $f(x)$.  
The global minimum $f(x)=0$ is at $(0,0)$ and is marked with an open 
white circle.}
\label{rast} 
\end{figure}

In order to minimize this function using \pkg{DEoptim}, 
the \proglang{R} interpreter is
invoked, and the package is loaded with the command 
<<prelim>>=
library("DEoptim")
@
The \code{DEoptim} function of the package \pkg{DEoptim}
searches for minima of the objective function between
lower and upper bounds on each parameter to be optimized.  Therefore
in the call to \code{DEoptim} we specify vectors that comprise the
lower and upper bounds; these vectors are the same length as the
parameter vector.  The call to \code{DEoptim} can be made as
<<opt>>=
est.ras <- DEoptim(rastrigin,lower=c(-5,-5),upper=c(5,5),
                   control=list(storepopfrom=1, trace=FALSE))
@ 


\begin{figure}[t!] 
  \centering
  \includegraphics[width=.8\textwidth]{Rastrigin2.jpg} 
  \caption{The population associated with various generations of a call
    to \code{DEoptim} as it searches for the minimum of the Rastrigin
    function (marked with an open white circle).  The minimum is consistently 
    determined within 200 generations using the default settings of 
    \code{DEoptim}.}
  \label{ex11}
\end{figure}


Note that the vector of parameters to be optimized must be the first
argument of the objective function \code{fn} passed to \code{DEoptim}.
The above call specifies the objective function to minimize,
\code{rastrigin}, the lower and upper bounds on the the parameters,
and, via the \code{control} argument, that we want to store
intermediate populations from the first generation onwards
(\code{storepopfrom = 1}), and do not want to print out progress
information each generation (\code{trace = FALSE}).  Storing
intermediate populations allows us to examine the progress of the
optimization in detail.  
Upon initialization, the population is
comprised of 50 vectors $x$ of length two 
(50 being the default value of \code{NP}), with $x_i$ a random value 
drawn from the uniform distribution over the values defined by the 
associated lower and upper bound. The operations of
crossover, mutation, and selection explained in Section~\ref{alg}
transform the population so that the members of successive generations
are more likely to represent the global minimum of the objective
function.  The members of the population generated by the above call 
are plotted at the end of
different generations in Figure~\ref{ex11}. 
\code{DEoptim} consistently finds the minimum of the function within 200
generations using the default settings.  We have observed that \pkg{DEoptim}
solves the Rastrigin problem more efficiently than  
the simulated annealing method found in
the \proglang{R} function \code{optim}. 

<<figure2-code,echo=FALSE,results=hide>>=
pushLayout <- function(nr, nc, name="layout") {
  pushViewport(viewport(layout=grid.layout(nr, nc,
                          just="left", widths=unit(rep(2, nc), "null")),
                        name=name))
  for (i in 1:nr) {
    for (j in 1:nc) {
      pushViewport(viewport(layout.pos.row=i, layout.pos.col=j))
      upViewport()
    }
  }
  upViewport()
}
names.vpPath <- names.viewport <- function(x) x$name

with.vpPath <- with.viewport <- function(data, expr, ...) {
  depth <- if (data$name == "ROOT") 0 else downViewport(names(data))
  result <- eval.parent(substitute(expr))
  upViewport(depth)
  invisible(result)
}

getChildren.viewport <- function(x) x$children  

## end functions for making the plots with lattice 
## specify number of cells to fill and number of rows

n <- 6
nr <- 2
nc <- ceiling(n/nr)
xy <- list(fontsize=list(text=12,points=10),
           par.xlab.text=list(cex=1.5),
           par.ylab.text=list(cex=1.5),
           axis.text=list(cex=1.5),
           par.main.text=list(cex=1.5),
           layout.widths=list(left.padding=.1, right.padding=.1,between=0),
           layout.heights=list(top.padding=.1, bottom.padding=.1,between=0))

jpeg("Rastrigin2.jpg")

grid.newpage()
downViewport(pushLayout(nr, nc))
vpt <- current.vpTree(all=FALSE)
plotat <- c(seq(10,50,by=10),1) 
## something strange with Sweave/grid interaction, gen.1 is getting 
## placed in wrong viewport; 'fixed' by permuting plotat above

for(k in 1:n) {
  i <- plotat[k]
  with(getChildren.viewport(vpt)[[k]],
       print(levelplot(z, row.values=x,column.values=y,
                       xlab=expression(x[1]), 
                       ylab=expression(x[2]), colorkey=FALSE,
                       par.settings=xy,between = list(x = .2),
                       col.regions=sequential_hcl(300),
                       main=paste("Generation",i), 
                       panel=function(z,row.values,column.values,...){
                         panel.levelplot(z,row.values,column.values,...);
                         panel.points(est.ras$member$storepop[[i]],
                                      pch=21,fill="black",col=1,cex=.5);
                         panel.points(0,0,pch=21,col="white",cex=1)}),
             newpage = FALSE))
}
dev.off() 
@ 

We note that as the dimensionality of the Rastrigin problem increases, 
\pkg{DEoptim} may not be able to find the global minimum in the default 
number of generations.  Heuristics to help ensure that the global minimum is 
found include re-running the problem with a larger population size (value
of \code{NP}), and increasing the maximum allowed number of generations.  

\subsection{Problems suitable for DE}\label{inex1} 

Differential Evolution does not require derivatives of the objective
function.  It is therefore useful in situations in which the objective
function is stochastic, noisy, or difficult to differentiate.  DE,
however, may be inefficient on smooth functions, where
derivative-based methods generally are most efficient.

In the example below, a generalized Rosenbrock function is considered.
This function is differentiable and has a single local minimum.  It is
often more efficient to apply methods other than DE to optimization of
such functions.  
Functions that are smooth but have many local minima, however, 
may still be good candidates for optimization with DE, since
alternative algorithms for local, as opposed to global, optimization 
may converge to a sub-optimal solution.

A generalized Rosenbrock function is possible 
to represent in \proglang{R} as 
<<opt,echo=FALSE,results=hide>>=
options(prompt = "R> ")
@ 
<<ban>>=
genrose.f <- function(x){
n <- length(x)
fval <- 1.0 + sum (100 * (x[1:(n-1)]^2 - x[2:n])^2 + (x[2:n] - 1)^2)
return(fval)
}
@ 

This function has a global minimum at 1, which \pkg{DEoptim} finds for 
$n = 10$ with a
call like: 
<<ban1>>=
n <- 10
ans <- DEoptim(fn=genrose.f, lower=rep(-5, n), upper=rep(5, n),
               control=list(NP=100, itermax=4000,trace=FALSE))
@ 

The minimum can be determined with far fewer function evalutations 
with a gradient-based method such as ``BFGS'' \citep{nash}, e.g., with the 
call
<<ban2>>=
ans1 <- optim(par=runif(10,-5,5), fn=genrose.f, method="BFGS",
              control=list(maxit=4000))
              
@ 
Note further that users interested in exact reproduction of results should 
set the seed of their random number generator before calling \pkg{DEoptim}.
DE is a randomized algorithm, and the results may vary between runs.

\section{The Differential Evolution algorithm}\label{alg} 

We sketch the classical DE algorithm here and refer
interested readers to the work of \citet{price} and
\citet{Price:Storn:Lampinen:06} for further elaboration.  
The algorithm is an
evolutionary technique which at each generation transforms a set of
parameter vectors, termed the population, into another set of parameter
vectors, the members of which are more likely to minimize the
objective function.  In order generate a new parameter vector, DE disturbs 
 an old parameter vector with the scaled difference of two randomly selected 
 parameter vectors.  

The variable $\mathit{NP}$ represents the number of
parameter vectors in the population.  At generation 0, $\mathit{NP}$ guesses
for the optimal value of the parameter vector are made, either using
random values between upper and lower bounds for each parameter or
using values given by the user.  
Each generation involves creation of a new population from the current
population members $x_{i,g}$, 
 where  $i$ indexes the
vectors that make up the population and 
$g$ indexes generation. 
This is
accomplished using {\sl differential mutation} of the population
members.  A trial mutant parameter vector $v_{i,g}$ is created by choosing
three members of the population, $x_{r0,g}$, $x_{r1,g}$ and
$x_{r2,g}$, at random.  Then $v_{i,g}$ is generated as
\begin{equation}
v_{i,g} \doteq x_{r0,g} + \text{F} \cdot (x_{r1,g} - x_{r2,g})
\label{de} 
\end{equation}
where $F$ is a positive scale factor.  Effective values of $\text{F}$ are 
typically less than 1. 

After the first mutation operation, mutation is continued until either
$\text{length}(x)$ mutations have been made or $\mathit{rand} > \mathit{CR}$,
where $\mathit{CR}$ 
is a crossover probability $\mathit{CR} \in [0,1]$, and where here and 
throughout $\mathit{rand}$ is used to denote a random number from 
$\mathcal{U}(0,1)$. The crossover probability $\mathit{CR}$
controls the fraction of the parameter values that are copied from the mutant.
$\mathit{CR}$ approximates but does not 
exactly represent the probability that a parameter value will be inherited 
from the mutant, since at least one mutation always occurs.  Mutation is applied
in this way to each member of the population.  

If an element $v_j$ of the parameter vector is found to violate the bounds
after mutation and crossover, it is reset, where here and throughout we use
$j$ to index into a parameter vector.
In the implementation of \pkg{DEoptim}, if $v_{j} >
\text{upper}_j$, it is reset as $v_j \doteq \text{upper}_j - \mathit{rand}
\cdot ( \text{upper}_j - \text{lower}_j)$, and if $v_{j} <
\text{lower}_j$, it is reset as $v_j \doteq \text{lower}_j + \mathit{rand}
\cdot ( \text{upper}_j - \text{lower}_j)$.  This ensures that candidate 
population members found to violate the bounds are set some random amount 
away from them, in such a way that the bounds are guaranteed to be satisfied.
Then the objective function
values associated with the children $v$ are determined.  If a trial
vector $v_{i,g}$ has equal or lower objective function value than the
vector $x_{i,g}$, $v_{i,g}$ replaces $x_{i,g}$ in the population;
otherwise $x_{i,g}$ remains.

The algorithm stops after some set number of generations, or after the objective 
function value associated with the best member has been reduced below some set 
threshold, or if it is unable to reduce the best member by a certain value over
over set number of iterations.

Variations on this theme are possible,
some of which are described in the following section.   
Values of  $\mathit{NP}$ and  $\mathit{CR}$ that have been 
found to be most effective for a variety of problems are described in 
\citet[Section~2]{Price:Storn:Lampinen:06}. Reasonable default values for many problems
are given in the following section. 

\section{Implementation}\label{imp} 

\pkg{DEoptim} was first published on the Comprehensive \proglang{R} Archive
Network (CRAN) in 2005 by David Ardia.   
Early versions were written in pure  \proglang{R}.
Since version 2.0-0 (published to CRAN in 2009 by Katharine Mullen) 
the package has relied on an
interface to  a \proglang{C} implementation of DE, which is significantly 
faster on most problems as compared to the implementation in pure \proglang{R}.
 Since version 2.0-3 the \proglang{C}
implementation dynamically allocates the memory required to store the
population, removing limitations on the number of members in the
population and length of the parameter vectors that may be optimized.

The implementation is used by calling the \proglang{R}
function \code{DEoptim}, the arguments of which are:
\begin{itemize}
\item \code{fn}: The objective function to be minimized.  This function 
  should have as its first argument the vector of real-valued parameters to optimize, and 
  return a scalar real result.  
\item \code{lower}, \code{upper}: Vectors specifying scalar real lower and upper 
  bounds on each parameter to be optimized, so that the $i$th element of
  \code{lower} and \code{upper} applies to the $i$th parameter.  The implementation
  searches between \code{lower} and \code{upper} for the global optimum of \code{fn}.
\item \code{control}: A list of control parameters, discussed below. 
  \item \code{...}: allows the user to pass additional arguments to the function \code{fn}.
\end{itemize}

The \code{control} argument is a list, 
the following elements of which are currently interpreted:
\begin{itemize}
\item \code{VTR}: The value to reach.  Specify the global minimum of
  \code{fn} if it is known, or if you wish to cease optimization after
  having reached a certain value.  The default value is \code{-Inf}.
\item \code{strategy}:  This defines the Differential Evolution
  strategy used in the optimization procedure, described below in the 
  terms used by \citet{Price:Storn:Lampinen:06}: 
  \begin{itemize}
  \item \code{1}: DE / rand / 1 / bin (classical strategy). 
    This strategy is the classical approach described in Section~\ref{alg}. 
  \item \code{2}: DE / local-to-best / 1 / bin. 
    In place of the classical DE mutation given in~\eqref{de}, 
    the expression
    \begin{align*}
      v_{i,g} \doteq \text{old}_{i,g} + \text{F} \cdot (\text{best}_{g} - \text{old}_{i,g}) + \text{F} \cdot (x_{r1,g} - x_{r2,g}) 
    \end{align*}
     is used, where  $\text{old}_{i,g}$ and $\text{best}_{g}$  are the 
     $i$th member and best member, respectively, of the previous population.
     This strategy is currently used by default.  
     
   \item \code{3}: DE / best / 1 / bin with jitter.
     In place of the classical DE mutation given in~\eqref{de}, 
     the expression
     \begin{align*}
       v_{i,g} \doteq \text{best}_{g} + \text{jitter} + \text{F} \cdot (x_{r1,g} - x_{r2,g}) 
     \end{align*}
     is used, where $\text{jitter}$ is defined as 
     $0.0001 \cdot \mathit{rand} + F$.
      \item \code{4}: DE / rand / 1 / bin with per vector dither.
     In place of the classical DE mutation given in~\eqref{de}, 
     the expression
     \begin{align*}
     v_{i,g} \doteq x_{r0,g} + \text{dither} \cdot (x_{r1,g} - x_{r2,g})
     \end{align*}
     is used, where $\text{dither}$ is calculated as 
     $\text{dither} \doteq F + \mathit{rand} \cdot (1 - F)$.
      \item \code{5}: DE / rand / 1 / bin with per generation dither.
     The strategy described for \code{4} is used, but $\text{dither}$
     is only determined once per-generation. 
      \item \code{6}: DE / current-to-p-best / 1.
     The top $\text(100*p)$ percent best solutions are used in the mutation,
     where $p$ is defined in $\text(0,1]$.
   \item any value not above: variation to DE / rand / 1 / bin: either-or 
     algorithm.
     In the case that $\mathit{rand} < 0.5$, 
     the classical strategy described for \code{1} is used.  Otherwise, the 
     expression
     \begin{align*}
       v_{i,g} \doteq  x_{r0,g} + 0.5 \cdot (F + 1.0) \cdot (x_{r1,g} + x_{r2,g} -  2 \cdot x_{r0,g})
     \end{align*}
     is used. 
  \end{itemize}
\item  \code{bs}: 
  If \code{FALSE} then every mutant will be tested against a
  member in the previous generation, and the best value will survive 
  into the next generation.  This is the standard trial vs. target
  selection described in Section~\ref{alg}.   If \code{TRUE} 
  then the old generation and \code{NP}
  mutants will be sorted by their associated objective function
  values, and the best \code{NP} vectors will proceed into the next
  generation (this is best-of-parent-and-child selection).
  The default value is \code{FALSE}.
\item \code{NP}:  Number of population members. The default value is \code{50}.
\item \code{itermax}: The maximum iteration (population generation) allowed.
  The default value is \code{200}.
\item \code{CR}: Crossover probability from interval [0,1]. The default
  value is \code{0.5}.
\item \code{F}: Stepsize from interval [0,2]. The default value is \code{0.8}.
\item \code{trace}: Positive integer or logical value indicating whether 
  printing of progress occurs at each iteration. The default value is
  \code{TRUE}.  If a positive integer is specified, printing occurs every
  \code{trace} iterations.  
\item \code{initialpop}: An initial population used as a starting
  population in the optimization procedure, specified as a matrix in which each row represents
  a population member.   May be useful to speed up
  convergence. Defaults to \code{NULL}, so  that 
  the initial population is generated randomly within 
  the lower and upper boundaries.
\item \code{storepopfrom}: From which generation should the following
  intermediate populations be stored in memory. Default to
  \code{itermax + 1}, i.e., no intermediate population is stored.
\item \code{storepopfreq}: The frequency with which populations
  are stored. The default value is \code{1}, i.e., every intermediate population
  is stored.
   \item \code{checkWinner}: Logical value indicating whether to re-evaluate
      the objective function using the winning parameter vector if this
      vector remains the same between
    generations.  This may be useful for the optimization of a noisy
    objective function.  If \code{checkWinner = TRUE} and 
    \code{avWinner = FALSE}
   then the  value associated with re-evaluation of
   the objective function is used in the next generation.
   Default to \code{FALSE}.
 \item \code{avWinner}: Logical value.  If  \code{checkWinner = TRUE} and
   \code{avWinner = TRUE} then the objective
   function value associated with the winning member represents the
   average of all evaluations of the objective function over the course
   of the `winning streak' of the best population member. This option
   may be useful for optimization of noisy objective functions, and is
   interpreted only if \code{checkWinner = TRUE}. 
   The default value is \code{TRUE}.
 \end{itemize} 
The default value of \code{control} is the return value of 
\code{DEoptim.control()}, which is  a list  with the above elements and 
specified default values.  

The return value of the \code{DEoptim} function is a member of the S3 class 
\code{DEoptim}.  Members of this class have a \code{plot} method that 
accepts the argument \code{plot.type}.  
When \code{retVal} is an object returned by 
\pkg{DEoptim}, calling \code{plot(retVal, plot.type = "bestmemit")} results in
 a plot of the parameter values that represent the lowest value of the 
 objective function each generation.  
 Calling \code{plot(retVal, plot.type = "bestvalit")} plots the best value 
 of the objective function each generation.  Calling 
  \code{plot(retVal, plot.type = "storepop")} results in a plot of stored 
  populations (which are only available if these have been saved by 
  setting the \code{control} argument of \code{DEoptim} appropriately).  
A summary method for objects of S3 class \code{DEoptim} also exists, 
and returns the best parameter vector, the best value of the objective function,
the number of generations optimization ran, and the number of times the 
objective function was evaluated. 

A note on recommended settings: We have set the default values
to the methods recommended by \citet{Price:Storn:Lampinen:06} as starting 
points.  We use \code{strategy = 2} by default; the user should 
consider trying as alternatives \code{strategy = 6} and  \code{strategy = 1}, 
though the best method will be highly problem-dependent.
Generally, the user should set the lower and upper bounds to 
exploit the full allowable numerical range, i.e., if a parameter 
is allowed to exhibit
values in the range [-1, 1] it is typically 
a good idea to pick the initial values from this
range instead of unnecessarily restricting diversity. 
Increasing the value for \code{NP} will mean greater likelihood of finding the
minimum, but run-time will be longer.  

\pkg{DEoptim} relies on repeated evaluation of the objective function
in order to move the population toward a global minimum.  Users
interested in making \pkg{DEoptim} run as fast as possible should
ensure that evaluation of the objective function is as efficient as
possible.  Using pure \proglang{R} code, this may often be accomplished
using vectorization.  Writing parts of the objective function in a
lower-level language like \proglang{C} or \proglang{Fortran}
may also increase speed.

\section*{Disclaimer}

The views expressed in this vignette are the sole responsibility of the
authors and do not necessarily reflect those of NIST and 
aeris CAPITAL AG.

\bibliography{DEoptim}

\end{document}
